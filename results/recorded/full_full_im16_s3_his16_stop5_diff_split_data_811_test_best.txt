
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 16
image_dim: 16
learning_rate: 0.001
load_weights: False
max_steps: 256
max_train_doms: 6400
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/full_full_im16_s3_his16_stop5_diff_split_data_811_test_best.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7200
start_valid_dom: 6400
state_dim: 3
stop_epoch_gap: 5
target_steps: 5
test_episodes: 800
train_episodes: 500
train_mode: full
valid_episodes: 800

-----full-----

 epochs: 0	 avg_reward: -354.094908	 step_diff: 10.560903episodes: 800	 success: 702.0	 success_rate: 0.8775

best_epoch: 0	 best_success: 0.8775	 avg_reward: -354.094908005	 step_diff: 10.5609028961

-----full-----

 epochs: 0	 avg_reward: -263.051956	 step_diff: 10.330811episodes: 800	 success: 721.0	 success_rate: 0.90125


 Test results:
 success_rate: 0.90125	 avg_reward: -263.051956248	 step_diff: 10.3308112652
-----full-----

 epochs: 1	 avg_reward: -345.625494	 step_diff: 10.882960episodes: 800	 success: 700.0	 success_rate: 0.875

-----full-----

 epochs: 2	 avg_reward: -337.144927	 step_diff: 11.844799episodes: 800	 success: 708.0	 success_rate: 0.885

best_epoch: 2	 best_success: 0.885	 avg_reward: -337.144927173	 step_diff: 11.8447986577

-----full-----

 epochs: 2	 avg_reward: -261.192969	 step_diff: 11.392254episodes: 800	 success: 735.0	 success_rate: 0.91875


 Test results:
 success_rate: 0.91875	 avg_reward: -261.192969394	 step_diff: 11.3922538113
-----full-----

 epochs: 3	 avg_reward: -395.002592	 step_diff: 12.677679episodes: 800	 success: 697.0	 success_rate: 0.87125

-----full-----

 epochs: 4	 avg_reward: -407.988682	 step_diff: 10.989488episodes: 800	 success: 693.0	 success_rate: 0.86625

-----full-----

 epochs: 5	 avg_reward: -342.280249	 step_diff: 11.609467episodes: 800	 success: 708.0	 success_rate: 0.885

-----full-----

 epochs: 6	 avg_reward: -381.315839	 step_diff: 12.312446episodes: 800	 success: 697.0	 success_rate: 0.87125

-----full-----

 epochs: 7	 avg_reward: -353.949175	 step_diff: 11.081207episodes: 800	 success: 702.0	 success_rate: 0.8775



 Best results:
	test
		avg_reward: -261.192969394
		log_epoch: 2
		success_rate: 0.91875
		step_diff: 11.3922538113
	valid
		avg_reward: -337.144927173
		log_epoch: 2
		success_rate: 0.885
		step_diff: 11.8447986577
