
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 32
image_dim: 32
learning_rate: 0.001
load_weights: False
max_steps: 256
max_train_doms: 7000
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/same_target_full_im32_s3_his32_ep200_train500_test1k.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7000
state_dim: 3
stop_epoch_gap: 10
target_steps: 5
test_episodes: 1000
train_episodes: 500
train_mode: same_target
train_steps: 1000000

-----both-----
epochs: 0	 avg_reward: -274.065764769
episodes: 1000	 success: 794.0	 success_rate: 0.794

[both] 	 best_epoch: 0	 best_success: 0.794	 avg_reward: -274.065764769

-----alpha-----
epochs: 0	 avg_reward: -562.731869742
episodes: 1000	 success: 602.0	 success_rate: 0.602

[alpha] 	 best_epoch: 0	 best_success: 0.602	 avg_reward: -562.731869742

-----beta-----
epochs: 0	 avg_reward: -554.409557799
episodes: 1000	 success: 792.0	 success_rate: 0.792

[beta] 	 best_epoch: 0	 best_success: 0.792	 avg_reward: -554.409557799


-----both-----
epochs: 1	 avg_reward: -259.829323643
episodes: 1000	 success: 836.0	 success_rate: 0.836

[both] 	 best_epoch: 1	 best_success: 0.836	 avg_reward: -259.829323643

-----alpha-----
epochs: 1	 avg_reward: -576.647209044
episodes: 1000	 success: 671.0	 success_rate: 0.671

[alpha] 	 best_epoch: 1	 best_success: 0.671	 avg_reward: -576.647209044

-----beta-----
epochs: 1	 avg_reward: -452.945496771
episodes: 1000	 success: 793.0	 success_rate: 0.793

[beta] 	 best_epoch: 1	 best_success: 0.793	 avg_reward: -452.945496771


-----both-----
epochs: 2	 avg_reward: -306.507235949
episodes: 1000	 success: 815.0	 success_rate: 0.815

-----both-----
epochs: 3	 avg_reward: -366.574802841
episodes: 1000	 success: 805.0	 success_rate: 0.805

-----both-----
epochs: 4	 avg_reward: -350.820672496
episodes: 1000	 success: 693.0	 success_rate: 0.693

-----both-----
epochs: 5	 avg_reward: -438.180151572
episodes: 1000	 success: 787.0	 success_rate: 0.787

-----both-----
epochs: 6	 avg_reward: -366.136966445
episodes: 1000	 success: 746.0	 success_rate: 0.746

-----both-----
epochs: 7	 avg_reward: -403.160293551
episodes: 1000	 success: 806.0	 success_rate: 0.806

-----both-----
epochs: 8	 avg_reward: -555.817067151
episodes: 1000	 success: 790.0	 success_rate: 0.79

-----both-----
epochs: 9	 avg_reward: -469.219957848
episodes: 1000	 success: 767.0	 success_rate: 0.767

-----both-----
epochs: 10	 avg_reward: -527.478653831
episodes: 1000	 success: 790.0	 success_rate: 0.79

-----both-----
epochs: 11	 avg_reward: -547.362926736
episodes: 1000	 success: 741.0	 success_rate: 0.741



 Best results:
alpha: {'avg_reward': -576.64720904391322, 'log_epoch': 1, 'success_rate': 0.671}
beta: {'avg_reward': -452.94549677116623, 'log_epoch': 1, 'success_rate': 0.793}
both: {'avg_reward': -259.82932364312705, 'log_epoch': 1, 'success_rate': 0.836}
