
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 32
image_dim: 32
learning_rate: 0.001
load_weights: False
max_steps: 512
max_train_doms: 7000
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/full_full_im32_s3_his32_ep200_train500_test1k_max512.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7000
state_dim: 3
stop_epoch_gap: 10
target_steps: 5
test_episodes: 1000
train_episodes: 500
train_mode: full
train_steps: 1000000

-----full-----
epochs: 0	 avg_reward: -265.470846055
episodes: 1000	 success: 934.0	 success_rate: 0.934

best_epoch: 0	 best_success: 0.934	 avg_reward: -265.470846055

-----full-----
epochs: 1	 avg_reward: -783.810752418
episodes: 1000	 success: 894.0	 success_rate: 0.894

-----full-----
epochs: 2	 avg_reward: -2148.0698479
episodes: 1000	 success: 616.0	 success_rate: 0.616

-----full-----
epochs: 3	 avg_reward: -928.585607132
episodes: 1000	 success: 858.0	 success_rate: 0.858

-----full-----
epochs: 4	 avg_reward: -596.907059819
episodes: 1000	 success: 872.0	 success_rate: 0.872

-----full-----
epochs: 5	 avg_reward: -1524.67558929
episodes: 1000	 success: 739.0	 success_rate: 0.739

-----full-----
epochs: 6	 avg_reward: -1476.57170301
episodes: 1000	 success: 803.0	 success_rate: 0.803

-----full-----
epochs: 7	 avg_reward: -1037.29799535
episodes: 1000	 success: 818.0	 success_rate: 0.818

-----full-----
epochs: 8	 avg_reward: -1179.84612475
episodes: 1000	 success: 828.0	 success_rate: 0.828

-----full-----
epochs: 9	 avg_reward: -1136.70344033
episodes: 1000	 success: 843.0	 success_rate: 0.843

-----full-----
epochs: 10	 avg_reward: -1707.60183181
episodes: 1000	 success: 769.0	 success_rate: 0.769



 Best results:
avg_reward: -265.470846055
log_epoch: 0
success_rate: 0.934
