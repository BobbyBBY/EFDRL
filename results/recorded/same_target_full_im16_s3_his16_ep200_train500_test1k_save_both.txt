
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 16
image_dim: 16
learning_rate: 0.001
load_weights: False
max_steps: 256
max_train_doms: 7000
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/same_target_full_im16_s3_his16_ep200_train500_test1k_save_both.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7000
state_dim: 3
stop_epoch_gap: 10
target_steps: 5
test_episodes: 1000
train_episodes: 500
train_mode: same_target
train_steps: 1000000

-----alpha-----
epochs: 0	 avg_reward: -680.618563446
episodes: 1000	 success: 786.0	 success_rate: 0.786

[alpha] 	 best_epoch: 0	 best_success: 0.786	 avg_reward: -680.618563446

-----beta-----
epochs: 0	 avg_reward: -525.621898441
episodes: 1000	 success: 851.0	 success_rate: 0.851

[beta] 	 best_epoch: 0	 best_success: 0.851	 avg_reward: -525.621898441

-----both-----
epochs: 0	 avg_reward: -366.99742508
episodes: 1000	 success: 875.0	 success_rate: 0.875

[both] 	 best_epoch: 0	 best_success: 0.875	 avg_reward: -366.99742508




 Best results:
alpha: {'avg_reward': -680.61856344644173, 'log_epoch': 0, 'success_rate': 0.786}
beta: {'avg_reward': -525.6218984410192, 'log_epoch': 0, 'success_rate': 0.851}
both: {'avg_reward': -366.99742507982484, 'log_epoch': 0, 'success_rate': 0.875}
