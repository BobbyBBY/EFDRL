
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 32
image_dim: 32
learning_rate: 0.001
load_weights: False
max_steps: 256
max_train_doms: 7000
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/full_full_im32_s3_his32_ep200_train500_test1k.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7000
state_dim: 3
stop_epoch_gap: 10
target_steps: 5
test_episodes: 1000
train_episodes: 500
train_mode: full
train_steps: 1000000

-----full-----
epochs: 0	 avg_reward: -214.475749929
episodes: 1000	 success: 838.0	 success_rate: 0.838

best_epoch: 0	 best_success: 0.838	 avg_reward: -214.475749929

-----full-----
epochs: 1	 avg_reward: -310.576028257
episodes: 1000	 success: 791.0	 success_rate: 0.791

-----full-----
epochs: 2	 avg_reward: -428.802691861
episodes: 1000	 success: 817.0	 success_rate: 0.817

-----full-----
epochs: 3	 avg_reward: -374.025874181
episodes: 1000	 success: 793.0	 success_rate: 0.793

-----full-----
epochs: 4	 avg_reward: -510.105860512
episodes: 1000	 success: 674.0	 success_rate: 0.674

-----full-----
epochs: 5	 avg_reward: -568.524056624
episodes: 1000	 success: 677.0	 success_rate: 0.677

-----full-----
epochs: 6	 avg_reward: -739.287417962
episodes: 1000	 success: 731.0	 success_rate: 0.731

-----full-----
epochs: 7	 avg_reward: -837.726275566
episodes: 1000	 success: 589.0	 success_rate: 0.589

-----full-----
epochs: 8	 avg_reward: -732.195166215
episodes: 1000	 success: 636.0	 success_rate: 0.636

-----full-----
epochs: 9	 avg_reward: -612.343534443
episodes: 1000	 success: 704.0	 success_rate: 0.704

-----full-----
epochs: 10	 avg_reward: -779.284107117
episodes: 1000	 success: 759.0	 success_rate: 0.759



 Best results:
avg_reward: -214.475749929
log_epoch: 0
success_rate: 0.838
