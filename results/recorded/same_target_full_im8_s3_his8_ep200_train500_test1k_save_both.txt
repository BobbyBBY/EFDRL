
 Arguments:
batch_size: 32
epochs: 200
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
gamma: 0.9
gpu_fraction: 0.2
hist_len: 8
image_dim: 8
learning_rate: 0.001
load_weights: False
max_steps: 256
max_train_doms: 7000
num_actions: 16
positive_rate: 0.9
predict_net: full
priority: 1
replay_size: 100000
result_dir: results/same_target_full_im8_s3_his8_ep200_train500_test1k_save_both.txt
reward_bound: 0.0
save_weights: True
start_epoch: 0
start_test_dom: 7000
state_dim: 3
stop_epoch_gap: 10
target_steps: 5
test_episodes: 1000
train_episodes: 500
train_mode: same_target
train_steps: 1000000

-----alpha-----
epochs: 0	 avg_reward: -519.854616058
episodes: 1000	 success: 753.0	 success_rate: 0.753

[alpha] 	 best_epoch: 0	 best_success: 0.753	 avg_reward: -519.854616058

-----beta-----
epochs: 0	 avg_reward: -202.409277823
episodes: 1000	 success: 939.0	 success_rate: 0.939

[beta] 	 best_epoch: 0	 best_success: 0.939	 avg_reward: -202.409277823

-----both-----
epochs: 0	 avg_reward: -74.1840461855
episodes: 1000	 success: 950.0	 success_rate: 0.95

[both] 	 best_epoch: 0	 best_success: 0.95	 avg_reward: -74.1840461855


-----alpha-----
epochs: 1	 avg_reward: -803.983535806
episodes: 1000	 success: 775.0	 success_rate: 0.775

[alpha] 	 best_epoch: 1	 best_success: 0.775	 avg_reward: -803.983535806

-----beta-----
epochs: 1	 avg_reward: -251.274697351
episodes: 1000	 success: 923.0	 success_rate: 0.923

-----both-----
epochs: 1	 avg_reward: -97.8135533386
episodes: 1000	 success: 959.0	 success_rate: 0.959

[both] 	 best_epoch: 1	 best_success: 0.959	 avg_reward: -97.8135533386


-----alpha-----
epochs: 2	 avg_reward: -288.116354106
episodes: 1000	 success: 894.0	 success_rate: 0.894

[alpha] 	 best_epoch: 2	 best_success: 0.894	 avg_reward: -288.116354106

-----beta-----
epochs: 2	 avg_reward: -359.541021439
episodes: 1000	 success: 886.0	 success_rate: 0.886

-----both-----
epochs: 2	 avg_reward: -44.1610324874
episodes: 1000	 success: 970.0	 success_rate: 0.97

[both] 	 best_epoch: 2	 best_success: 0.97	 avg_reward: -44.1610324874




 Best results:
alpha: {'avg_reward': -288.11635410597631, 'log_epoch': 2, 'success_rate': 0.894}
beta: {'avg_reward': -202.4092778229643, 'log_epoch': 0, 'success_rate': 0.939}
both: {'avg_reward': -44.161032487351562, 'log_epoch': 2, 'success_rate': 0.97}
